{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox61Jknz6Dte"
      },
      "outputs": [],
      "source": [
        "!pip install keras\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install tensorflow\n",
        "!pip install lime\n",
        "!pip install json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2-gGVYo_KUb",
        "outputId": "464882c6-9e7e-4629-964e-e88ecd5bc4d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9yAlfVL0jne"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import PIL\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "import os\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.layers import Dense, Flatten\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import lime\n",
        "from lime import lime_image\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdR9t78i1ydE"
      },
      "outputs": [],
      "source": [
        "!wget \"http://seppe.net/aa/assignment2/images.zip\"\n",
        "!7z x images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_HtYuKC32dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f70196af-a083-4c9f-9614-c087c4e1cc06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdqZ8FRjbSzl"
      },
      "outputs": [],
      "source": [
        "! rm images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3yf9caQ5FJJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "images_path = '/content/images'\n",
        "dataset_path = '/content/gdrive/My Drive/dataset.json'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyMYuVPC5vnv"
      },
      "source": [
        "Extract the price categories and store them in a library where they are linked to images. (We will later need this as a dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StzBljSJ5fwq"
      },
      "outputs": [],
      "source": [
        "with open(dataset_path, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "price_categories = {}\n",
        "image_ids = []\n",
        "for item in data:\n",
        "    # Check if 'price_category' key is present in the 'item' dictionary\n",
        "    if 'price_category' in item and item['price_category'] is not None:\n",
        "        # Extract the price category\n",
        "        price_category = item['price_category']['label']\n",
        "        # Extract the image IDs from the \"full_images\" list and map them to their price category\n",
        "        for img in item[\"more_details\"][\"full_images\"]:\n",
        "            image_id = img[\"image_id\"]\n",
        "            image_ids.append(image_id)\n",
        "            price_categories[image_id] = price_category\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf4B92iD6RoH"
      },
      "source": [
        "Now I have a list of image id's and a library of price categories.\n",
        "The file names of the images are just the id with .jpg behind it.\n",
        "I want to create the training, validation and test set.\n",
        "For this I need to make a pandas data frame with two columns, with the image file names and one with the categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpcmtlhi62LX"
      },
      "source": [
        "First, we shuffle the image id's and then split them up in training, validation and test set lists of image id's.(The training, validation, test sizes are 70%, 20% and 10%. We could, however **change these values 0.7, 0.2, 0.1 to lower values if we want to use less of the data**.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC_6BcQK6eDk"
      },
      "outputs": [],
      "source": [
        "random.shuffle(image_ids)  # shuffle image id's\n",
        "\n",
        "train_size = 0.7\n",
        "val_size = 0.2\n",
        "test_size = 0.1\n",
        "\n",
        "train_image_ids = image_ids[:int(len(image_ids) * train_size)]\n",
        "val_image_ids = image_ids[int(len(image_ids) * train_size):int(len(image_ids) * (train_size + val_size))]\n",
        "test_image_ids = image_ids[int(len(image_ids) * (train_size + val_size)):int(len(image_ids) * (train_size + val_size + test_size))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqDmaBMo7A-h"
      },
      "source": [
        "Now we create lists of the filenames of these images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKlFQ-Nu6tCS"
      },
      "outputs": [],
      "source": [
        "train_filenames = [f\"{image_id}.jpg\" for image_id in train_image_ids]\n",
        "val_filenames = [f\"{image_id}.jpg\" for image_id in val_image_ids]\n",
        "test_filenames = [f\"{image_id}.jpg\" for image_id in test_image_ids]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKSWOfHO7NdG"
      },
      "source": [
        "Now, we create a pandas dataframe with two columns: \"filename\" and \"price_category\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG3noLTe7QZG"
      },
      "outputs": [],
      "source": [
        "train_df = pd.DataFrame(\n",
        "    {\"id\": train_filenames, \"label\": [price_categories[image_id] for image_id in train_image_ids]})\n",
        "val_df = pd.DataFrame(\n",
        "    {\"id\": val_filenames, \"label\": [price_categories[image_id] for image_id in val_image_ids]})\n",
        "test_df = pd.DataFrame(\n",
        "    {\"id\": test_filenames, \"label\": [price_categories[image_id] for image_id in test_image_ids]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rZ1tjSR7iJ7"
      },
      "source": [
        "We set the paths for the training, validation, and test data directories and create the directories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PNxNMKa7yC8"
      },
      "source": [
        "We set the paths for the training, validation, and test data directories and create the directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "743xyvxt6zr6"
      },
      "outputs": [],
      "source": [
        "# delete the directories if they are there already\n",
        "if os.path.exists('/content/images/train'):\n",
        "    shutil.rmtree('/content/images/train')\n",
        "else:\n",
        "    print(f\"The folder '{'/content/images/train'}' does not exist yet.\")\n",
        "\n",
        "if os.path.exists('/content/images/val'):\n",
        "    shutil.rmtree('/content/images/val')\n",
        "else:\n",
        "    print(f\"The folder '{'/content/images/val'}' does not exist yet.\")\n",
        "\n",
        "if os.path.exists('/content/images/test'):\n",
        "    shutil.rmtree('/content/images/test')\n",
        "else:\n",
        "    print(f\"The folder '{'/content/images/test'}' does not exist yet.\")\n",
        "\n",
        "# Set the paths for the training, validation, and test data directories\n",
        "train_data_dir = os.path.join(images_path, \"train\")\n",
        "val_data_dir = os.path.join(images_path, \"val\")\n",
        "test_data_dir = os.path.join(images_path, \"test\")\n",
        "\n",
        "# Create the directories if they don't exist already\n",
        "!mkdir -p \"{train_data_dir}\"\n",
        "!mkdir -p \"{val_data_dir}\"\n",
        "!mkdir -p \"{test_data_dir}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5yxY8iL70Qx"
      },
      "source": [
        "We move the image files to the appropriate directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2an_sH3I_5RR"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def is_image_corrupted(image_path):\n",
        "    try:\n",
        "        Image.open(image_path)\n",
        "        return False\n",
        "    except (IOError, SyntaxError):\n",
        "        return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1Vsr91l74LQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36bc09a-57a6-40ef-a160-817bf5205358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corrupted image: 4215425.jpg\n"
          ]
        }
      ],
      "source": [
        "for filename in train_filenames:\n",
        "    src_path = os.path.join(images_path, filename)\n",
        "    dst_path = os.path.join(train_data_dir, filename)\n",
        "    is_corrupted = is_image_corrupted(src_path)\n",
        "    if is_corrupted:\n",
        "        print(f\"corrupted image: {filename}\")\n",
        "    else:\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "for filename in val_filenames:\n",
        "    src_path = os.path.join(images_path, filename)\n",
        "    dst_path = os.path.join(val_data_dir, filename)\n",
        "    is_corrupted = is_image_corrupted(src_path)\n",
        "    if is_corrupted:\n",
        "        print(f\"corrupted image: {filename}\")\n",
        "    else:\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "for filename in test_filenames:\n",
        "    src_path = os.path.join(images_path, filename)\n",
        "    dst_path = os.path.join(test_data_dir, filename)\n",
        "    is_corrupted = is_image_corrupted(src_path)\n",
        "    if is_corrupted:\n",
        "        print(f\"corrupted image: {filename}\")\n",
        "    else:\n",
        "        shutil.copy(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qxGLyur78AJ"
      },
      "source": [
        "Now we want to preprocess the data and then generate it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU7I-sIA8ET2"
      },
      "source": [
        "We first define the image dimensions and the batch size. **(Change this, see what works best)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnN2pDNm8OzT"
      },
      "outputs": [],
      "source": [
        "img_width, img_height = 224, 224\n",
        "batch_size = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76zB8ctT8Yft"
      },
      "source": [
        "We use ImageDataGenerator for preprocessing including rotation augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pcP1WNg8hEn"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1. / 255, rotation_range=20, fill_mode='nearest')\n",
        "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH8dsZSY85E-"
      },
      "source": [
        "We generate the training, validation, and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oneLQYysrwLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b39f82ae-e56d-44c4-a0dc-013c7221342d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"id\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 80961 validated image filenames belonging to 4 classes.\n",
            "Found 23132 validated image filenames belonging to 4 classes.\n",
            "Found 11566 validated image filenames belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train_df,\n",
        "        directory='/content/images/train',\n",
        "        target_size=(224,224),\n",
        "        x_col=\"id\",\n",
        "        y_col=\"label\",\n",
        "        seed=42,\n",
        "        shuffle=True,\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=256)\n",
        "\n",
        "validation_generator = val_datagen.flow_from_dataframe(\n",
        "        dataframe = val_df,\n",
        "        directory='/content/images/val',\n",
        "        target_size=(224,224),\n",
        "        x_col=\"id\",\n",
        "        y_col=\"label\",\n",
        "        seed=42,\n",
        "        shuffle=True,\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=256)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = test_df,\n",
        "        directory='/content/images/test',\n",
        "        target_size=(224,224),\n",
        "        x_col=\"id\",\n",
        "        y_col=\"label\",\n",
        "        seed=42,\n",
        "        shuffle=False,\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIh45Yfp9AbW"
      },
      "source": [
        "Now we can finally build our Neural Network. We created one by hand at first, and then used a pretrained model (VGG16) to compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnMaw7ar9ao1"
      },
      "source": [
        "Define the CNN structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49pjF2_z9Yaw"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9uCOxmr9dxj"
      },
      "source": [
        "Compile the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8CuxvPz9h0O"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_PtQqly9ikU"
      },
      "source": [
        "Train the model.(**Number of epochs can be changed**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0ZgNxh09m5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28fbcca7-fad3-42ad-a60a-5ffd2bea4a03"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-971392841fde>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_generator, steps_per_epoch=train_generator.samples // batch_size, epochs=5,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            " 98/316 [========>.....................] - ETA: 35:35 - loss: 1.3429 - accuracy: 0.4171"
          ]
        }
      ],
      "source": [
        "history = model.fit_generator(train_generator, steps_per_epoch=train_generator.samples // batch_size, epochs=5,\n",
        "                              validation_data=validation_generator, validation_steps=validation_generator.samples // batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYf9TBa9-M8m"
      },
      "source": [
        "Evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9ueSghU-Q2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1422f014-bcfa-4d15-a4c1-abd8a6e51f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-416c9d65b6c8>:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.4071180522441864\n",
            "Test loss: 1.255115032196045\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Test loss:', test_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzek8u6o-R0x"
      },
      "source": [
        "Interpreter LIME\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UTs_J3r-UCh"
      },
      "outputs": [],
      "source": [
        "explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "\n",
        "def predict_wrapper(images):\n",
        "    # This function is a wrapper around the model's prediction function\n",
        "    # It takes in a batch of images (N, 224, 224, 3) and returns the predicted probabilities (N, 5)\n",
        "    return model.predict(images)\n",
        "\n",
        "\n",
        "# Get an example image from the validation set\n",
        "example_image_path = os.path.join(val_data_dir, val_filenames[0])\n",
        "example_image = Image.open(example_image_path)\n",
        "\n",
        "# Explain the model's prediction for the example image\n",
        "explanation = explainer.explain_instance(np.array(example_image), predict_wrapper, top_labels=5)\n",
        "\n",
        "# Show the LIME visualization for the explanation\n",
        "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
        "img_boundry = mark_boundaries(temp/2 + 0.5, mask)\n",
        "Image.fromarray((img_boundry*255).astype(np.uint8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9P21CzA-bgD"
      },
      "source": [
        "Now, we do the same thing but with the pretrained model VGG16."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv5sMW7li9ee"
      },
      "source": [
        "We first preprocess and generate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Oe7g_gBjEwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457dcb9b-2be0-4ef0-d672-9976c9eea4d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8096 validated image filenames belonging to 4 classes.\n",
            "Found 2313 validated image filenames belonging to 4 classes.\n",
            "Found 1157 validated image filenames belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# preprocessing according to VGG16\n",
        "batch_size = 64\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255, rotation_range=90,\n",
        "                                     brightness_range=[0.1, 0.7],\n",
        "                                     width_shift_range=0.5,\n",
        "                                     height_shift_range=0.5,\n",
        "                                     horizontal_flip=True,\n",
        "                                     vertical_flip=True,\n",
        "                                     validation_split=0.15,\n",
        "                                     preprocessing_function=preprocess_input)\n",
        "val_datagen = ImageDataGenerator(rescale=1. / 255,preprocessing_function=preprocess_input)\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255,preprocessing_function=preprocess_input)\n",
        "\n",
        "# Generate the training, validation, and testing datasets (I followed the instructions on https://www.learndatasci.com/tutorials/hands-on-transfer-learning-keras/)\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train_df,\n",
        "        directory='/content/images/train',\n",
        "        target_size=(224,224),\n",
        "        x_col=\"id\",\n",
        "        y_col=\"label\",\n",
        "        seed=42,\n",
        "        shuffle=True,\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=64)\n",
        "\n",
        "validation_generator = val_datagen.flow_from_dataframe(\n",
        "        dataframe = val_df,\n",
        "        directory='/content/images/val',\n",
        "        target_size=(224,224),\n",
        "        x_col=\"id\",\n",
        "        y_col=\"label\",\n",
        "        seed=42,\n",
        "        shuffle=True,\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=64)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = test_df,\n",
        "        directory='/content/images/test',\n",
        "        target_size=(224,224),\n",
        "        x_col=\"id\",\n",
        "        y_col=\"label\",\n",
        "        seed=42,\n",
        "        shuffle=False,\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=64)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y2452ok-0C-"
      },
      "source": [
        "Load without the top layer input_shape(img_width, img_height, 3) (the 3 is for the colors rbg)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDR-mYWu-xK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c1c89f-12db-4f95-a5a5-4f1d5e7b6472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in vgg_model.layers:\n",
        "    layer.trainable = False\n",
        "    # This is to make sure we don't train these layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReBGx9JP_E8h"
      },
      "source": [
        "We add a new output layer with 4 categories. Then we create the new model with the pretrained layers and our new output layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3DTqsuN_FKR"
      },
      "outputs": [],
      "source": [
        "x = Flatten()(vgg_model.output)\n",
        "output_layer = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model_VGG = Model(inputs=vgg_model.input, outputs=output_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0pHvnq7_SAu"
      },
      "source": [
        "Compile the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyU12H0q_VCB"
      },
      "outputs": [],
      "source": [
        "model_VGG.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pyVb_Iu_VMd"
      },
      "source": [
        "Train the model. (**Number of epochs can be changed**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiCLdcKS_W1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a382b9-a1ae-4c28-8713-dd3b9f0dc63b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-e56505b42464>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model_VGG.fit_generator(train_generator, steps_per_epoch=train_generator.samples // batch_size, epochs=5,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "126/126 [==============================] - 409s 3s/step - loss: 1.4088 - accuracy: 0.3757 - val_loss: 1.5636 - val_accuracy: 0.4180\n",
            "Epoch 2/5\n",
            "126/126 [==============================] - 363s 3s/step - loss: 1.3792 - accuracy: 0.3729 - val_loss: 1.5009 - val_accuracy: 0.3637\n",
            "Epoch 3/5\n",
            "126/126 [==============================] - 384s 3s/step - loss: 1.3917 - accuracy: 0.3797 - val_loss: 1.9117 - val_accuracy: 0.3294\n",
            "Epoch 4/5\n",
            "126/126 [==============================] - 386s 3s/step - loss: 1.3997 - accuracy: 0.3744 - val_loss: 1.6004 - val_accuracy: 0.3832\n",
            "Epoch 5/5\n",
            "126/126 [==============================] - 371s 3s/step - loss: 1.3777 - accuracy: 0.3790 - val_loss: 1.8566 - val_accuracy: 0.3225\n"
          ]
        }
      ],
      "source": [
        "history = model_VGG.fit_generator(train_generator, steps_per_epoch=train_generator.samples // batch_size, epochs=5,\n",
        "                              validation_data=validation_generator, validation_steps=validation_generator.samples // batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lBbD7rO_q4a"
      },
      "source": [
        "Evaluate the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTqXorN7_s2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ec5374-b22b-4726-c517-d3da287cad41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-bee26fdafaac>:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  test_loss, test_acc = model_VGG.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.3220486044883728\n",
            "Test loss: 1.8300116062164307\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model_VGG.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Test loss:', test_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpCyg39q_tvx"
      },
      "source": [
        "LIME interpreter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR3cDmIW_vR6"
      },
      "outputs": [],
      "source": [
        "explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "\n",
        "def predict_wrapper_VGG(images):\n",
        "    # This function is a wrapper around the model's prediction function\n",
        "    # It takes in a batch of images (N, 224, 224, 3) and returns the predicted probabilities (N, 5)\n",
        "    return model_VGG.predict(images)\n",
        "\n",
        "\n",
        "# Get an example image from the validation set\n",
        "example_image_path = os.path.join(val_data_dir, val_filenames[0])\n",
        "example_image = Image.open(example_image_path)\n",
        "\n",
        "# Explain the model's prediction for the example image\n",
        "explanation = explainer.explain_instance(np.array(example_image), predict_wrapper_VGG, top_labels=5)\n",
        "\n",
        "# Show the LIME visualization for the explanation\n",
        "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
        "img_boundry = mark_boundaries(temp/2 + 0.5, mask)\n",
        "Image.fromarray((img_boundry*255).astype(np.uint8))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, for the ResNet50 pretrained model"
      ],
      "metadata": {
        "id": "5BzZnCHKJ2F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import ResNet50\n",
        "\n",
        "# Preprocessing\n",
        "batch_size = 64\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=90,\n",
        "    brightness_range=[0.1, 0.7],\n",
        "    width_shift_range=0.5,\n",
        "    height_shift_range=0.5,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    validation_split=0.15,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function=preprocess_input)\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function=preprocess_input)\n",
        "\n",
        "# Generate the training, validation, and testing datasets\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory='/content/images/train',\n",
        "    target_size=(224, 224),\n",
        "    x_col=\"id\",\n",
        "    y_col=\"label\",\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory='/content/images/val',\n",
        "    target_size=(224, 224),\n",
        "    x_col=\"id\",\n",
        "    y_col=\"label\",\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory='/content/images/test',\n",
        "    target_size=(224, 224),\n",
        "    x_col=\"id\",\n",
        "    y_col=\"label\",\n",
        "    seed=42,\n",
        "    shuffle=False,\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# Load the ResNet50 model\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of the ResNet50 model\n",
        "for layer in resnet_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add your own classification layers on top of the ResNet50 model\n",
        "x = Flatten()(resnet_model.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "output_layer = Dense(4, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "model_resnet = Model(inputs=resnet_model.input, outputs=output_layer)\n",
        "\n",
        "# Compile and train the model\n",
        "model_resnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_resnet = model_resnet.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=5,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuHjb52TJ6DZ",
        "outputId": "3fe35343-8ef8-451c-d13d-952f92d4ff57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8096 validated image filenames belonging to 4 classes.\n",
            "Found 2313 validated image filenames belonging to 4 classes.\n",
            "Found 1157 validated image filenames belonging to 4 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 3s 0us/step\n",
            "Epoch 1/5\n",
            "126/126 [==============================] - 383s 3s/step - loss: 2.1067 - accuracy: 0.3723 - val_loss: 1.4252 - val_accuracy: 0.4236\n",
            "Epoch 2/5\n",
            "126/126 [==============================] - 374s 3s/step - loss: 1.2843 - accuracy: 0.3897 - val_loss: 1.2930 - val_accuracy: 0.3238\n",
            "Epoch 3/5\n",
            "126/126 [==============================] - 372s 3s/step - loss: 1.2664 - accuracy: 0.3893 - val_loss: 1.3119 - val_accuracy: 0.4240\n",
            "Epoch 4/5\n",
            "126/126 [==============================] - 354s 3s/step - loss: 1.2572 - accuracy: 0.3979 - val_loss: 1.2930 - val_accuracy: 0.4236\n",
            "Epoch 5/5\n",
            "126/126 [==============================] - 354s 3s/step - loss: 1.2515 - accuracy: 0.4011 - val_loss: 1.2611 - val_accuracy: 0.4240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model_resnet.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Test loss:', test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KazJDjkqfap3",
        "outputId": "aeac0b11-e6fd-4ef9-96d6-4fe36b7dfd85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-3eab6bae4f73>:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  test_loss, test_acc = model_resnet.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.40625\n",
            "Test loss: 1.2785124778747559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for EfficientNet"
      ],
      "metadata": {
        "id": "BMw8DWleLwoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet\n",
        "from keras.applications import EfficientNetB0\n",
        "\n",
        "\n",
        "# Preprocessing\n",
        "batch_size = 64\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=90,\n",
        "    brightness_range=[0.1, 0.7],\n",
        "    width_shift_range=0.5,\n",
        "    height_shift_range=0.5,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    validation_split=0.15,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function=preprocess_input)\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function=preprocess_input)\n",
        "\n",
        "# Generate the training, validation, and testing datasets\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory='/content/images/train',\n",
        "    target_size=(224, 224),\n",
        "    x_col=\"id\",\n",
        "    y_col=\"label\",\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory='/content/images/val',\n",
        "    target_size=(224, 224),\n",
        "    x_col=\"id\",\n",
        "    y_col=\"label\",\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory='/content/images/test',\n",
        "    target_size=(224, 224),\n",
        "    x_col=\"id\",\n",
        "    y_col=\"label\",\n",
        "    seed=42,\n",
        "    shuffle=False,\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# Load the EfficientNetB0 model\n",
        "efficientnet_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of the EfficientNetB0 model\n",
        "for layer in efficientnet_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add your own classification layers on top of the EfficientNetB0 model\n",
        "x = Flatten()(efficientnet_model.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "output_layer = Dense(4, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "model_efficientnet = Model(inputs=efficientnet_model.input, outputs=output_layer)\n",
        "\n",
        "# Compile and train the model\n",
        "model_efficientnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_efficientnet = model_efficientnet.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=5,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDESkLogLzVD",
        "outputId": "7f37b626-bb25-4852-a999-90c34f38b93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.22.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (8.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (23.1)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n",
            "Found 8096 validated image filenames belonging to 4 classes.\n",
            "Found 2313 validated image filenames belonging to 4 classes.\n",
            "Found 1157 validated image filenames belonging to 4 classes.\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 1s 0us/step\n",
            "Epoch 1/5\n",
            "126/126 [==============================] - 378s 3s/step - loss: 3.7321 - accuracy: 0.3490 - val_loss: 1.2722 - val_accuracy: 0.4236\n",
            "Epoch 2/5\n",
            "126/126 [==============================] - 372s 3s/step - loss: 1.3177 - accuracy: 0.3643 - val_loss: 1.2846 - val_accuracy: 0.4232\n",
            "Epoch 3/5\n",
            "126/126 [==============================] - 350s 3s/step - loss: 1.3406 - accuracy: 0.3687 - val_loss: 1.2473 - val_accuracy: 0.4249\n",
            "Epoch 4/5\n",
            "126/126 [==============================] - 349s 3s/step - loss: 1.3323 - accuracy: 0.3594 - val_loss: 1.4003 - val_accuracy: 0.3190\n",
            "Epoch 5/5\n",
            "126/126 [==============================] - 343s 3s/step - loss: 1.2929 - accuracy: 0.3668 - val_loss: 1.2697 - val_accuracy: 0.4232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model_efficientnet.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Test loss:', test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-ycdyicnhpV",
        "outputId": "c812cb25-a5cc-44ed-ccd4-682787ae0e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-a4aa1a68026b>:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  test_loss, test_acc = model_efficientnet.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.40625\n",
            "Test loss: 1.2800960540771484\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}